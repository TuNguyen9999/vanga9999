import requests
from bs4 import BeautifulSoup
from datetime import datetime, timedelta
from telegram import Update
from telegram.ext import Application, CommandHandler, MessageHandler, filters
import time
import re
import asyncio
import httpx
import smtplib
import ssl
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart

# ================== Cáº¤U HÃŒNH ==================
TELEGRAM_BOT_TOKEN = "7200591128:AAFtBUbfLpp-OoI9II9hQArMTZFwelTT6_Y"

# ================== Cáº¤U HÃŒNH EMAIL ==================
# QUAN TRá»ŒNG: Äiá»n thÃ´ng tin cá»§a báº¡n vÃ o Ä‘Ã¢y.
# Äá»‘i vá»›i Gmail, báº¡n cáº§n dÃ¹ng "Máº­t kháº©u á»©ng dá»¥ng" thay vÃ¬ máº­t kháº©u Ä‘Äƒng nháº­p thÃ´ng thÆ°á»ng.
EMAIL_SENDER = "vcamnews@gmail.com"  # Email ngÆ°á»i gá»­i
EMAIL_PASSWORD = "dsel ocad nqqj hdxy"    # DÃ¡n máº­t kháº©u á»©ng dá»¥ng 16 kÃ½ tá»± cá»§a báº¡n vÃ o Ä‘Ã¢y
EMAIL_RECIPIENT = "tunguyen3214@gmail.com" # Email ngÆ°á»i nháº­n
SMTP_SERVER = "smtp.gmail.com" # MÃ¡y chá»§ SMTP cho Gmail
SMTP_PORT = 465 # Cá»•ng SMTP cho Gmail (sá»­ dá»¥ng SSL)
# ====================================================

# ==============================================
# Danh sÃ¡ch mÃ£ cá»• phiáº¿u cáº§n theo dÃµi
# Báº¡n cÃ³ thá»ƒ thay Ä‘á»•i, thÃªm hoáº·c bá»›t cÃ¡c mÃ£ cá»• phiáº¿u trong danh sÃ¡ch dÆ°á»›i Ä‘Ã¢y.
tickers = [
    "HUT", "FLC"
]

# CÃ¡c URL cáº§n crawl
urls_to_crawl = [
    "https://cafef.vn/thi-truong-chung-khoan.chn",  # Thá»‹ trÆ°á»ng chá»©ng khoÃ¡n
    "https://cafef.vn/doanh-nghiep.chn",  # Doanh nghiá»‡p
    "https://cafef.vn/tai-chinh-ngan-hang.chn",  # TÃ i chÃ­nh - NgÃ¢n hÃ ng
    "https://cafef.vn/bat-dong-san.chn",  # Báº¥t Ä‘á»™ng sáº£n
    "https://vietnambiz.vn/doanh-nghiep.htm",
    "https://vietnambiz.vn/chung-khoan.htm",
    "https://vietnambiz.vn/tai-chinh.htm"
]


def check_stock_in_soup(soup, tickers):
    """Kiá»ƒm tra mÃ£ cá»• phiáº¿u trong ná»™i dung tá»« Ä‘á»‘i tÆ°á»£ng BeautifulSoup."""
    content_selectors = [
        ".detail-content", ".detail-content-body", ".news-content",
        "article", ".content-detail", "#mainContent"
    ]
    for selector in content_selectors:
        content_element = soup.select_one(selector)
        if content_element:
            content = content_element.get_text().upper()
            for ticker in tickers:
                ticker_upper = ticker.upper()
                patterns = [
                    f"\\({ticker_upper}\\)", f"\\[{ticker_upper}\\]",
                    f":\\s*{ticker_upper}\\b", f":{ticker_upper}\\b",
                    f"MÃƒ:\\s*{ticker_upper}\\b", f"MÃƒ\\s+{ticker_upper}\\b",
                ]
                for pattern in patterns:
                    if re.search(pattern, content):
                        return ticker
    return None

def parse_date_from_soup(soup):
    """Láº¥y ngÃ y Ä‘Äƒng bÃ i tá»« Ä‘á»‘i tÆ°á»£ng BeautifulSoup."""
    date_selectors = [
        "span.pdate", "span.date", ".post-time", ".time", ".datepost",
        "span[class*='time']", "span[class*='date']", ".article-time",
        ".news-time",
        "span.datetime" # ThÃªm selector cho Vietnambiz
    ]
    for selector in date_selectors:
        date_element = soup.select_one(selector)
        if date_element:
            date_text = date_element.get_text()
            date_patterns = [
                r"(\d{2}-\d{2}-\d{4})", r"(\d{2}/\d{2}/\d{4})",
                r"(\d{2}-\d{2}-\d{4} - \d{2}:\d{2} [AP]M)",
                r"(\d{1,2}/\d{1,2}/\d{4})", r"(\d{1,2}-\d{1,2}/\d{4})"
            ]
            for pattern in date_patterns:
                match = re.search(pattern, date_text)
                if match:
                    date_str = match.group(1)
                    try:
                        if "-" in date_str:
                            return datetime.strptime(date_str, "%d-%m-%Y")
                        else:
                            return datetime.strptime(date_str, "%d/%m/%Y")
                    except ValueError:
                        try:
                            if "-" in date_str:
                                return datetime.strptime(date_str, "%-d-%-m-%Y")
                            else:
                                return datetime.strptime(date_str, "%-d/%-m/%Y")
                        except ValueError:
                            continue
    return None

def get_page_urls(url, page=1):
    """Láº¥y URL cho trang phÃ¢n trang má»™t cÃ¡ch chÃ­nh xÃ¡c vÃ  an toÃ n."""
    if page == 1:
        return url
    if "vietnambiz.vn" in url:
        # VÃ­ dá»¥: https://vietnambiz.vn/doanh-nghiep.htm -> https://vietnambiz.vn/doanh-nghiep/trang-2.htm
        return url.replace(".htm", f"/trang-{page}.htm")
    # Thay tháº¿ pháº§n Ä‘uÃ´i .chn báº±ng /trang-{page}.chn cho Cafef
    return url.replace(".chn", f"/trang-{page}.chn")

async def fetch_cafef(target_date_str=None):
    """
    TÃ¬m náº¡p tin tá»©c tá»« Cafef cho má»™t ngÃ y cá»¥ thá»ƒ báº±ng httpx Ä‘á»ƒ cÃ³ hiá»‡u nÄƒng cao.
    """
    if target_date_str:
        try:
            if '-' in target_date_str:
                target_date = datetime.strptime(target_date_str, "%d-%m-%Y").date()
            else:
                target_date = datetime.strptime(target_date_str, "%d/%m/%Y").date()
        except ValueError:
            target_date = datetime.now().date()
    else:
        target_date = datetime.now().date()

    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36"
    }
    data = []
    processed_urls = set()

    article_selectors_cafef = ", ".join([
        ".knswli-title a", ".newscontent h3 a", ".top_noibat h3 a",
        ".list_news_home h3 a", ".tlitem h3 a", ".box-title a",
        "article h3 a", ".visit-popup", ".title a",
        ".story__heading a", ".news-item a", ".list-news a"
    ])
    article_selectors_vietnambiz = ", ".join(["h3.title-list-news a"])


    async with httpx.AsyncClient(headers=headers, timeout=20.0, follow_redirects=True) as client:
        for base_url in urls_to_crawl:
            
            # Chá»n bá»™ selector vÃ  URL gá»‘c phÃ¹ há»£p vá»›i trang web
            if "vietnambiz.vn" in base_url:
                article_selector_str = article_selectors_vietnambiz
                site_base_url = "https://vietnambiz.vn"
            else: # Máº·c Ä‘á»‹nh lÃ  cafef.vn
                article_selector_str = article_selectors_cafef
                site_base_url = "https://cafef.vn"

            for page in range(1, 4):
                list_url = get_page_urls(base_url, page)
                print(f"Äang truy cáº­p: {list_url}") # ThÃªm dÃ²ng nÃ y Ä‘á»ƒ gá»¡ lá»—i
                try:
                    list_res = await client.get(list_url)
                    # Náº¿u gáº·p trang khÃ´ng cÃ³ (404), bá» qua vÃ  tiáº¿p tá»¥c
                    if list_res.status_code == 404:
                        continue
                    list_res.raise_for_status()
                except httpx.RequestError as e:
                    print(f"Lá»—i khi táº£i trang danh sÃ¡ch {e.request.url}: {e}")
                    continue

                list_soup = BeautifulSoup(list_res.text, 'html.parser')

                for article_link in list_soup.select(article_selector_str):
                    try:
                        title = article_link.get_text(strip=True)
                        article_url = article_link.get('href', '')

                        if not title or not article_url:
                            continue

                        if article_url.startswith('/'):
                            article_url = site_base_url + article_url
                        elif not article_url.startswith('http'):
                            continue

                        if article_url in processed_urls:
                            continue
                        processed_urls.add(article_url)

                        try:
                            article_res = await client.get(article_url)
                            article_res.raise_for_status()
                        except httpx.RequestError as e:
                            print(f"Lá»—i khi táº£i bÃ i viáº¿t {e.request.url}: {e}")
                            continue

                        article_soup = BeautifulSoup(article_res.text, 'html.parser')
                        date_posted = parse_date_from_soup(article_soup)

                        if not date_posted or date_posted.date() != target_date:
                            continue

                        ticker = check_stock_in_soup(article_soup, tickers)
                        if ticker:
                            data.append({
                                "MÃ£ cá»• phiáº¿u": ticker,
                                "TiÃªu Ä‘á»": title,
                                "ÄÆ°á»ng link": article_url,
                                "NgÃ y Ä‘Äƒng": date_posted.strftime("%d/%m/%Y")
                            })
                    except Exception as e:
                        print(f"Lá»—i khi xá»­ lÃ½ bÃ i viáº¿t {article_url}: {e}")
                        continue
    return data

def format_news_for_email(news_data, display_date_str):
    """Äá»‹nh dáº¡ng danh sÃ¡ch tin tá»©c thÃ nh má»™t chuá»—i HTML Ä‘áº¹p máº¯t cho email."""
    html = f"""
    <html>
    <head>
        <style>
            body {{ font-family: Arial, sans-serif; line-height: 1.6; }}
            .container {{ padding: 20px; border: 1px solid #ddd; border-radius: 5px; max-width: 700px; margin: auto; }}
            .header {{ font-size: 22px; font-weight: bold; color: #333; border-bottom: 2px solid #eee; padding-bottom: 10px; margin-bottom: 20px;}}
            .news-item {{ border-bottom: 1px solid #eee; padding: 15px 0; }}
            .news-item:last-child {{ border-bottom: none; }}
            .ticker {{ font-weight: bold; color: #0056b3; font-size: 1.1em; }}
            .title {{ font-weight: bold; color: #333; }}
            a {{ color: #007bff; text-decoration: none; font-weight: bold;}}
            a:hover {{ text-decoration: underline; }}
        </style>
    </head>
    <body>
        <div class="container">
            <p class="header">ğŸ“° Tin tá»©c chá»©ng khoÃ¡n ngÃ y {display_date_str}</p>
    """
    for item in news_data:
        html += f"""
            <div class="news-item">
                <span class="ticker">ğŸ“ˆ MÃ£ CP: {item['MÃ£ cá»• phiáº¿u']}</span><br>
                <span class="title">ğŸ“„ {item['TiÃªu Ä‘á»']}</span><br>
                <a href="{item['ÄÆ°á»ng link']}">ğŸ”— Äá»c thÃªm</a>
            </div>
        """
    html += """
        </div>
    </body>
    </html>
    """
    return html

def send_email(subject, html_content, sender, recipient, password):
    """Gá»­i email vá»›i ná»™i dung HTML báº±ng Gmail (sá»­ dá»¥ng SSL)."""
    if sender == "your_email@gmail.com" or password == "your_app_password":
        msg = "ThÃ´ng tin email chÆ°a Ä‘Æ°á»£c cáº¥u hÃ¬nh trong file main.py. Bá» qua viá»‡c gá»­i mail."
        print(f"Cáº¢NH BÃO: {msg}")
        return False, msg

    message = MIMEMultipart("alternative")
    message["Subject"] = subject
    message["From"] = sender
    message["To"] = recipient

    message.attach(MIMEText(html_content, "html"))
    context = ssl.create_default_context()
    try:
        # Sá»­ dá»¥ng SMTP_SSL cho Gmail trÃªn cá»•ng 465
        with smtplib.SMTP_SSL(SMTP_SERVER, SMTP_PORT, context=context) as server:
            server.login(sender, password)
            server.sendmail(sender, recipient, message.as_string())
        print(f"Email Ä‘Ã£ Ä‘Æ°á»£c gá»­i thÃ nh cÃ´ng tá»›i {recipient}")
        return True, f"Email Ä‘Ã£ Ä‘Æ°á»£c gá»­i thÃ nh cÃ´ng tá»›i {recipient}"
    except Exception as e:
        error_msg = f"Lá»—i khi gá»­i email: {e}"
        print(error_msg)
        return False, error_msg


async def news_command_handler(update: Update, context):
    """Xá»­ lÃ½ lá»‡nh /news, tÃ¬m náº¡p, hiá»ƒn thá»‹ vÃ  gá»­i tin tá»©c qua email."""
    
    target_date_str = None
    # Kiá»ƒm tra xem ngÆ°á»i dÃ¹ng cÃ³ cung cáº¥p ngÃ y khÃ´ng
    if context.args:
        target_date_str = context.args[0]
        try:
            # Chá»‰ kiá»ƒm tra Ä‘á»‹nh dáº¡ng, khÃ´ng chuyá»ƒn Ä‘á»•i á»Ÿ Ä‘Ã¢y
            if '-' in target_date_str:
                datetime.strptime(target_date_str, "%d-%m-%Y")
            elif '/' in target_date_str:
                datetime.strptime(target_date_str, "%d/%m/%Y")
            else:
                await update.message.reply_text("âŒ Äá»‹nh dáº¡ng ngÃ y khÃ´ng há»£p lá»‡. Vui lÃ²ng sá»­ dá»¥ng `dd-mm-yyyy` hoáº·c `dd/mm/yyyy`.")
                return
        except ValueError:
            await update.message.reply_text("âŒ NgÃ y khÃ´ng há»£p lá»‡. Vui lÃ²ng sá»­ dá»¥ng Ä‘á»‹nh dáº¡ng `dd-mm-yyyy` hoáº·c `dd/mm/yyyy`.\nVÃ­ dá»¥: `/news 21-04-2025`")
            return

    # XÃ¡c Ä‘á»‹nh chuá»—i ngÃ y Ä‘á»ƒ hiá»ƒn thá»‹
    if target_date_str:
        display_date_str = target_date_str.replace('-', '/')
    else:
        display_date_str = datetime.now().strftime('%d/%m/%Y')

    await update.message.reply_text(f"ğŸ” Äang tÃ¬m náº¡p tin tá»©c cho ngÃ y {display_date_str}, vui lÃ²ng chá»...")

    try:
        # Truyá»n chuá»—i ngÃ y má»¥c tiÃªu vÃ o hÃ m fetch_cafef
        news_data = await fetch_cafef(target_date_str)

        if not news_data:
            await update.message.reply_text(f"ğŸ˜• KhÃ´ng tÃ¬m tháº¥y tin tá»©c nÃ o cho ngÃ y {display_date_str}.")
            return

        # Äá»‹nh dáº¡ng vÃ  gá»­i pháº£n há»“i
        header = f"<b>ğŸ“° Tin tá»©c chá»©ng khoÃ¡n ngÃ y {display_date_str}</b>\n"
        header += "--------------------------------------\n"
        await update.message.reply_text(header, parse_mode='HTML')

        # Gá»­i tá»«ng tin má»™t
        for item in news_data:
            response = ""
            response += f"ğŸ“ˆ <b>MÃ£ CP:</b> {item['MÃ£ cá»• phiáº¿u']}\n"
            response += f"ğŸ“„ <b>TiÃªu Ä‘á»:</b> {item['TiÃªu Ä‘á»']}\n"
            response += f"ğŸ”— <a href=\"{item['ÄÆ°á»ng link']}\">Äá»c thÃªm</a>\n"
            await update.message.reply_text(response, parse_mode='HTML', disable_web_page_preview=True)

        # Sau khi gá»­i tin lÃªn Telegram, tiáº¿n hÃ nh gá»­i email
        await update.message.reply_text("ğŸ“§ Äang chuáº©n bá»‹ gá»­i email...")
        subject = f"Tin tá»©c chá»©ng khoÃ¡n ngÃ y {display_date_str}"
        html_content = format_news_for_email(news_data, display_date_str)

        # Cháº¡y hÃ m gá»­i mail Ä‘á»“ng bá»™ trong má»™t thread riÃªng Ä‘á»ƒ khÃ´ng block bot
        success, message = await asyncio.to_thread(
            send_email,
            subject,
            html_content,
            EMAIL_SENDER,
            EMAIL_RECIPIENT,
            EMAIL_PASSWORD
        )

        if success:
            await update.message.reply_text(f"âœ… {message}")
        else:
            await update.message.reply_text(f"âŒ {message}")

    except Exception as e:
        print(f"Lá»—i khi xá»­ lÃ½ lá»‡nh /news: {e}")
        await update.message.reply_text("âŒ Ráº¥t tiáº¿c, Ä‘Ã£ cÃ³ lá»—i xáº£y ra trong quÃ¡ trÃ¬nh tÃ¬m náº¡p tin tá»©c.")

async def help_message_handler(update: Update, context):
    """Gá»­i tin nháº¯n hÆ°á»›ng dáº«n khi ngÆ°á»i dÃ¹ng nháº¯n tin thÃ´ng thÆ°á»ng."""
    await update.message.reply_text("ğŸ‘‹ ChÃ o báº¡n! Vui lÃ²ng sá»­ dá»¥ng lá»‡nh /news [dd-mm-yyyy] Ä‘á»ƒ nháº­n tin tá»©c. Náº¿u khÃ´ng nháº­p ngÃ y, bot sáº½ láº¥y tin tá»©c hÃ´m nay.")


def main():
    app = Application.builder().token(TELEGRAM_BOT_TOKEN).build()
    
    # ThÃªm trÃ¬nh xá»­ lÃ½ cho lá»‡nh /news
    app.add_handler(CommandHandler("news", news_command_handler))
    
    # ThÃªm trÃ¬nh xá»­ lÃ½ cho cÃ¡c tin nháº¯n vÄƒn báº£n khÃ¡c Ä‘á»ƒ hÆ°á»›ng dáº«n ngÆ°á»i dÃ¹ng
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, help_message_handler))

    print("ğŸ¤– Bot Ä‘ang cháº¡y... Gá»­i lá»‡nh /news [dd-mm-yyyy] Ä‘á»ƒ báº¯t Ä‘áº§u.")
    app.run_polling()

if __name__ == '__main__':
    main()
